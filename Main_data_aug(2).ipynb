{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random as rn\n",
    "import os\n",
    "import sys\n",
    "os.environ['PYTHONHASHSEED'] = '0'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "# random seed for numpy\n",
    "# np.random.seed(0)\n",
    "# random seed for python\n",
    "# rn.seed(0)\n",
    "# random seed for tensorflow\n",
    "# tf.random.set_seed(0)\n",
    "\n",
    "import pandas as pd\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import csv\n",
    "import glob\n",
    "# from itertools import chain\n",
    "from keras import models\n",
    "from keras import layers\n",
    "import keras \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.callbacks import History\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import CubicSpline      # for warping\n",
    "from transforms3d.axangles import axangle2mat  # for rotation\n",
    "\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a path like \"../trial/S01/ACC_01.parquet\" return:\n",
    "# the number of ms that a file needs in order to do the downsampling;\n",
    "# and return the type among:\n",
    "# - 0 (EDA)\n",
    "# - 1 (BVP)\n",
    "# - 2 (ACC)\n",
    "# - 3 (TEM) \n",
    "\n",
    "# If the file is incorrect return -1\n",
    "def type_file(name):\n",
    "    name_file = name.split('/')[3][:3]\n",
    "#     print(name_file)\n",
    "    if name_file == 'EDA':\n",
    "        return 0, 0\n",
    "    elif name_file == 'BVP':\n",
    "        return '250ms', 1\n",
    "    elif name_file == 'ACC':\n",
    "        return '250ms', 2\n",
    "    elif name_file == 'TEM':\n",
    "        return 0, 5\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to determine the most frequent element in a list:\n",
    "# [0,0,0,1,1] return 0\n",
    "# [0,0,1,1,1] return 1\n",
    "\n",
    "def most_frequent(List):\n",
    "    counter = 0\n",
    "    num = List[0]\n",
    "\n",
    "    for i in List:\n",
    "        curr_frequency = List.count(i)\n",
    "        if(curr_frequency> counter):\n",
    "            counter = curr_frequency\n",
    "            num = i\n",
    "    return num\n",
    "\n",
    "# listt = [0,1,0,1]\n",
    "# print(most_frequent(listt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_data_and_fill_missing_nan(ARRAY, df, value):\n",
    "    for i in range(0, df.shape[0]):\n",
    "        ARRAY.append(df[value][i])\n",
    "\n",
    "    if (len(ARRAY) % 2400) != 0:\n",
    "        rounding = int(len(ARRAY)//2400 + (len(ARRAY) % 2400 > 0))\n",
    "        number_cells = rounding * 2400\n",
    "        missing_zeros = [np.nan] * (number_cells - len(ARRAY))\n",
    "        ARRAY = ARRAY + missing_zeros\n",
    "    return ARRAY\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_sleep_label(LABEL, EDA, df):\n",
    "    i = 0\n",
    "    list_sleep = []\n",
    "#     create the list_sleep with all the values of the colums 'Sleep'\n",
    "    for j in range(0, df.shape[0]):\n",
    "        value = df['Sleep'][j].astype(np.float64)\n",
    "        list_sleep.append(value)\n",
    "\n",
    "#   for each 2400 window choose if 0 or 1, and append it to ARRAR_LABEL\n",
    "    while i in range(0, len(list_sleep)- 2399):\n",
    "        list_sleep_window = list_sleep[i:(i+2400)]\n",
    "        label_sleep = most_frequent(list_sleep_window)\n",
    "        LABEL.append(label_sleep)\n",
    "        i += 2400\n",
    "        \n",
    "#     if EDA len is greather than ARRAY_LABEL, uniform it to the same length\n",
    "    if (len(LABEL) < int(len(EDA)/2400)):\n",
    "        missing_zeros = [np.nan]*(int(len(EDA)/2400)-len(LABEL))\n",
    "        LABEL = LABEL + missing_zeros\n",
    "        \n",
    "#     print(len(LABEL))\n",
    "    return LABEL\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_zeros_to_uniform_size_array(ARRAY, missing_zeros):\n",
    "    ARRAY = [np.nan]* missing_zeros\n",
    "    return ARRAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_arrays(ARRAY, ARR2, ARR3, ARR4, ARR5, ARR6, LABEL):\n",
    "    array_zeros = np.zeros(2400)\n",
    "    \n",
    "    array_boolean = np.isnan(ARRAY).any(axis=1)\n",
    "\n",
    "    # iterate over each row.\n",
    "    # if delete a \"true\" then continue in a while untill it goes 1 step forward\n",
    "    i = 0\n",
    "    while i < len(array_boolean):\n",
    "        while array_boolean[i]:\n",
    "            ARRAY = np.delete(ARRAY, i, 0)\n",
    "            ARR2 = np.delete(ARR2, i, 0)\n",
    "            ARR3 = np.delete(ARR3, i, 0)\n",
    "            ARR4 = np.delete(ARR4, i, 0)\n",
    "            ARR5 = np.delete(ARR5, i, 0)\n",
    "            ARR6 = np.delete(ARR6, i, 0)\n",
    "            LABEL = np.delete(LABEL, i, 0)\n",
    "            array_boolean = np.delete(array_boolean, i)\n",
    "        i += 1\n",
    "    \n",
    "#     print(ARRAY.shape)\n",
    "    ARRAY = ARRAY[:-1]\n",
    "    ARR2 = ARR2[:-1]\n",
    "    ARR3 = ARR3[:-1]\n",
    "    ARR4 = ARR4[:-1]\n",
    "    ARR5 = ARR5[:-1]\n",
    "    ARR6 = ARR6[:-1]\n",
    "    LABEL = LABEL[:-1]\n",
    "    return ARRAY, ARR2, ARR3, ARR4, ARR5, ARR6, LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from array 1D, i create an array 2D with the last row as 0.\n",
    "def reshape_arrays(EDA):\n",
    "    EDA = np.array(EDA)\n",
    "#     print(\"eda before: \",EDA.shape)\n",
    "    EDA = EDA.reshape(1,len(EDA)//2400, 2400)\n",
    "    array_zeros = np.zeros(2400)\n",
    "    EDA = EDA[0]\n",
    "    EDA = np.concatenate((EDA, [array_zeros]), axis=0)\n",
    "    \n",
    "#     print(\"eda after: \",EDA.shape)\n",
    "    return EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 687,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from array 1D, i append a 0 in the last row.\n",
    "def reshape_label(LABEL):\n",
    "    LABEL = np.array(LABEL)\n",
    "#     print(\"LABEL before: \", LABEL.shape)\n",
    "#     LABEL = LABEL.reshape(1,len(LABEL), 1)\n",
    "#     array_zeros = np.zeros(2400)\n",
    "#     LABEL = LABEL[0]\n",
    "    LABEL = np.concatenate((LABEL, [0]), axis=0)\n",
    "    \n",
    "#     print(\"LABEL after: \",LABEL.shape)\n",
    "    return LABEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 688,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Call function create_train_set_train_label so that we have the two zero tensors.\n",
    "# for each file read the data, downsampling the data and fill the tensors.\n",
    "\n",
    "def read_data(files):\n",
    "    EDA, BVP, ACC_X, ACC_Y, ACC_Z, TEM, LABEL = [],[],[],[],[],[],[]\n",
    "\n",
    "\n",
    "    # READ ALL THE FILES and DOWNSAMPLING\n",
    "    for name_file in files:\n",
    "#         print(name_file)\n",
    "        rounding, number_cells, missing_zeros = 0, 0, []\n",
    "        # DataFrame\n",
    "        table = pd.read_parquet(name_file, engine='pyarrow')\n",
    "        # creating DataFrame\n",
    "        df = pd.DataFrame(table)\n",
    "        # converting timestamp\n",
    "        timestamp_col = pd.to_datetime(df['timestamp'], unit='s')\n",
    "        df['timestamp'] = timestamp_col\n",
    "        # get if file it's among EDA, BVP, ACC, ST, otherwise return error\n",
    "        arr_type = type_file(name_file)\n",
    "        if arr_type == -1:\n",
    "            print(\"Error in the file name\")\n",
    "            return -1\n",
    "\n",
    "        # RESAMPLE the tensor\n",
    "        # 0 means it's already 4Hz, otherwise resample with '250ms'\n",
    "        if arr_type[0] != 0:\n",
    "            df = df.resample(arr_type[0], on='timestamp').mean()\n",
    "            df = df.reset_index()\n",
    "        \n",
    "        # remove the          \n",
    "        \n",
    "#         print(df.shape)\n",
    "       # CREATES THE ARRAYS\n",
    "        # create linear arrays as sequences of elements. for each file add several zeros to complete a window of 2400     \n",
    "        if arr_type[1] == 0:\n",
    "            EDA = append_data_and_fill_missing_nan(EDA, df, 'value')\n",
    "            LABEL = find_sleep_label(LABEL, EDA, df)\n",
    "                \n",
    "        elif arr_type[1] == 1:\n",
    "            BVP = append_data_and_fill_missing_nan(BVP, df, 'value')\n",
    "\n",
    "        elif arr_type[1] == 2:\n",
    "            ACC_X = append_data_and_fill_missing_nan(ACC_X, df, 'X')\n",
    "            ACC_Y = append_data_and_fill_missing_nan(ACC_Y, df, 'Y')\n",
    "            ACC_Z = append_data_and_fill_missing_nan(ACC_Z, df, 'Z')\n",
    "            \n",
    "        elif arr_type[1] == 5:\n",
    "            TEM = append_data_and_fill_missing_nan(TEM, df, 'value')\n",
    "        \n",
    "        \n",
    "#     print(\"LEN LABEL\",len(LABEL))\n",
    "#     if each file has the same length it doesn make sense to check it. only in between files fill the row of zeros\n",
    "#     and then start from the next row a new file\n",
    "#     if the files are not the same quantity, it's better to throw error?\n",
    "    uniform_len = max(len(EDA),len(BVP),len(ACC_X),len(ACC_Y),len(ACC_Z),len(TEM))    \n",
    "#     print(len(EDA), ' ',len(BVP), ' ',len(ACC_X), ' ',len(ACC_Y), ' ',len(ACC_Z), ' ',len(TEM) )\n",
    "#     check train_set\n",
    "    if len(EDA) != uniform_len:\n",
    "        EDA = EDA + [np.nan]* (uniform_len - len(EDA))\n",
    "    if len(BVP) != uniform_len:\n",
    "        BVP = BVP + [np.nan]* (uniform_len - len(BVP))\n",
    "    if len(ACC_X) != uniform_len:\n",
    "        ACC_X = ACC_X + [np.nan]* (uniform_len - len(ACC_X))\n",
    "    if len(ACC_Y) != uniform_len:\n",
    "        ACC_Y = ACC_Y + [np.nan]* (uniform_len - len(ACC_Y))\n",
    "    if len(ACC_Z) != uniform_len:\n",
    "        ACC_Z = ACC_Z + [np.nan]* (uniform_len - len(ACC_Z))\n",
    "    if len(TEM) != uniform_len:\n",
    "        TEM = TEM + [np.nan]* (uniform_len - len(TEM))\n",
    "        \n",
    "#     print(len(EDA_LABEL), ' ',len(BVP_LABEL), ' ',len(ACC_X_LABEL), ' ',len(ACC_Y_LABEL), ' ',len(ACC_Z_LABEL), ' ',len(TEM_LABEL) )\n",
    "    \n",
    "    \n",
    "    # convert the list to a numpy array\n",
    "#     removing rows with nan\n",
    "    EDA_np, BVP_np, TEM_np = np.array(EDA),np.array(BVP),np.array(TEM)\n",
    "    ACC_X_np, ACC_Y_np, ACC_Z_np = np.array(ACC_X),np.array(ACC_Y),np.array(ACC_Z)\n",
    "    LABEL_np = np.array(LABEL)\n",
    "\n",
    "    \n",
    "    EDA_np = reshape_arrays(EDA)\n",
    "    BVP_np = reshape_arrays(BVP)\n",
    "    ACC_X_np = reshape_arrays(ACC_X)\n",
    "    ACC_Y_np = reshape_arrays(ACC_Y)\n",
    "    ACC_Z_np = reshape_arrays(ACC_Z)\n",
    "    TEM_np = reshape_arrays(TEM)\n",
    "    LABEL_np =  reshape_label(LABEL)\n",
    "\n",
    "    \n",
    "\n",
    "    EDA_np, BVP_np, ACC_X_np, ACC_Y_np, ACC_Z_np, TEM_np,LABEL_np = remove_nan_arrays(EDA_np, BVP_np, ACC_X_np, ACC_Y_np, ACC_Z_np, TEM_np, LABEL_np)\n",
    "# each file has different nan rows\n",
    "    BVP_np, EDA_np, ACC_X_np, ACC_Y_np, ACC_Z_np, TEM_np,LABEL_np = remove_nan_arrays(BVP_np, EDA_np, ACC_X_np, ACC_Y_np, ACC_Z_np, TEM_np,LABEL_np)\n",
    "    ACC_X_np, EDA_np, BVP_np, ACC_Y_np, ACC_Z_np, TEM_np,LABEL_np = remove_nan_arrays(ACC_X_np, EDA_np, BVP_np, ACC_Y_np, ACC_Z_np, TEM_np,LABEL_np)\n",
    "    ACC_Y_np, EDA_np, BVP_np, ACC_X_np, ACC_Z_np, TEM_np,LABEL_np = remove_nan_arrays(ACC_Y_np, EDA_np, BVP_np, ACC_X_np, ACC_Y_np, TEM_np,LABEL_np)\n",
    "    ACC_Z_np, EDA_np, BVP_np, ACC_X_np, ACC_Y_np, TEM_np,LABEL_np = remove_nan_arrays(ACC_Z_np, EDA_np, BVP_np, ACC_X_np, ACC_Y_np, TEM_np,LABEL_np)\n",
    "    TEM_np, EDA_np, BVP_np, ACC_X_np, ACC_Y_np, ACC_Z_np,LABEL_np = remove_nan_arrays(TEM_np, EDA_np, BVP_np, ACC_X_np, ACC_Y_np, ACC_Z_np,LABEL_np)\n",
    "\n",
    "    \n",
    "#     print(EDA_np.shape)\n",
    "#     print(BVP_np.shape)\n",
    "#     print(ACC_X_np.shape)\n",
    "#     print(ACC_Y_np.shape)\n",
    "#     print(ACC_Z_np.shape)\n",
    "#     print(TEM_np.shape)\n",
    "#     print(LABEL_np.shape)\n",
    "    \n",
    "\n",
    "    EDA = EDA_np.flatten().tolist()\n",
    "    BVP = BVP_np.flatten().tolist()\n",
    "    ACC_X = ACC_X_np.flatten().tolist()\n",
    "    ACC_Y = ACC_Y_np.flatten().tolist()\n",
    "    ACC_Z = ACC_Z_np.flatten().tolist()\n",
    "    TEM = TEM_np.flatten().tolist()\n",
    "    \n",
    "    \n",
    "    train_set = np.array([EDA, BVP, ACC_X, ACC_Y, ACC_Z, TEM],dtype=np.float64)\n",
    "    train_label = np.array([LABEL_np], dtype=np.float64)\n",
    "    \n",
    "\n",
    "    # Reshape the tensor train set, counting the number of rows dividing by 2400\n",
    "    uniform_len = max(len(EDA),len(BVP),len(ACC_X),len(ACC_Y),len(ACC_Z),len(TEM))    \n",
    "    row_training_set = uniform_len // 2400\n",
    "    if (uniform_len % 2400) != 0:\n",
    "        return \"Error in missing_zeros\"\n",
    "    \n",
    "    train_set = train_set.reshape(6,row_training_set,2400)\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_set_augmented, label_set_augmented = augment_data(train_set, train_label)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    print(\"shape before dstack\")\n",
    "    print(train_set.shape)\n",
    "    print(train_label.shape)\n",
    "    print(train_set_augmented.shape)\n",
    "    print(label_set_augmented.shape)\n",
    "    \n",
    "    train_set = np.dstack(train_set)\n",
    "    train_label = train_label.reshape(train_label.shape[1], 1)\n",
    "    \n",
    "    train_set_augmented = np.dstack(train_set_augmented)\n",
    "    label_set_augmented = label_set_augmented.reshape(label_set_augmented.shape[1], 1)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(\"shape after dstack\")\n",
    "    print(train_set.shape)\n",
    "    print(train_label.shape)\n",
    "    print(train_set_augmented.shape)\n",
    "    print(label_set_augmented.shape)\n",
    "    \n",
    "    \n",
    "\n",
    "    return train_set, train_label, train_set_augmented, label_set_augmented"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma = 0.05\n",
    "\n",
    "# #### Hyperparameters :  sigma = standard devitation (STD) of the noise\n",
    "def jitter(X, sigma=0.05):\n",
    "    myNoise = np.random.normal(loc=0, scale=sigma, size=X.shape)\n",
    "    print(\"jitter\")\n",
    "    return X + myNoise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 690,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(start_session, end_session):\n",
    "#     create list of folders\n",
    "    listt = os.listdir(\"../Sessions/\")\n",
    "\n",
    "#   how many users? for now only 1\n",
    "    list_dir = sorted(listt)[0:10]\n",
    "#     list_dir = sorted(listt)\n",
    "    list_path_dir = []\n",
    "    for elem in list_dir:\n",
    "        list_path_dir.append(\"../Sessions/\" + elem)\n",
    "\n",
    "#     read files in the folder and create a list of files \n",
    "    list_ordered_files = []\n",
    "    \n",
    "    for folder in list_path_dir:\n",
    "#         print(folder)\n",
    "        list_files = []\n",
    "        for infile in os.listdir(folder):\n",
    "            list_files.append(infile)\n",
    "        list_files = sorted(list_files)\n",
    "#         print(list_files)\n",
    "\n",
    "    #     divide the list into 4 sections: acc, bvp, eda, temp\n",
    "    #     take one from each and construct a list \n",
    "    #     the order is really important while reading files\n",
    "        \n",
    "        acc = []\n",
    "        bvp = []\n",
    "        eda = []\n",
    "        tem = []\n",
    "        for elem in (list_files):\n",
    "            if elem[:3] == \"ACC\":\n",
    "                acc.append(elem)\n",
    "            elif elem[:3] == \"BVP\":\n",
    "                bvp.append(elem)\n",
    "            elif elem[:3] == \"EDA\":\n",
    "                eda.append(elem)\n",
    "            elif elem[:3] == \"TEM\":\n",
    "                tem.append(elem)\n",
    "\n",
    "        acc = acc[start_session:end_session]\n",
    "        bvp = bvp[start_session:end_session]\n",
    "        eda = eda[start_session:end_session]\n",
    "        tem = tem[start_session:end_session]\n",
    "    #     create a list with that order: [acc1, bvp1, eda1, tem1, acc2, bvp2, eda2, tem2,...]\n",
    "        for i in range(len(acc)):\n",
    "            list_ordered_files.append(folder + \"/\" + acc[i])\n",
    "            list_ordered_files.append(folder + \"/\" + bvp[i])\n",
    "            list_ordered_files.append(folder + \"/\" + eda[i])\n",
    "            list_ordered_files.append(folder + \"/\" + tem[i])\n",
    "#     print(list_ordered_files)\n",
    "        \n",
    "    \n",
    "    return read_data(list_ordered_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def augment_data(train_set, train_label):\n",
    "    ARR,LABEL = [], []\n",
    "    print(\"start augmenting\")\n",
    "    print(train_set.shape)\n",
    "    print(train_label.shape)\n",
    "    # select random indices\n",
    "#     number_of_rows = int(train_set.shape[1] * 0.9)\n",
    "\n",
    "#     random indices has to be the same for every dimension so that the label can be accurate\n",
    "    random_indices = np.sort(np.random.choice(train_set.shape[1]-1, size=int(number_of_rows), replace=False))\n",
    "    #     iterate over every dimension \n",
    "    for train_set_one in train_set:\n",
    "    # take partial array with random indices\n",
    "        train_set_one = train_set_one[random_indices,:]\n",
    "    # perform jittering on the partial array\n",
    "#         train_set_one = scale(train_set_one)\n",
    "        train_set_one = jitter(train_set_one)\n",
    "        train_set_one = DA_MagWarp(train_set_one)\n",
    "\n",
    "        \n",
    "#     create an array ARR only of augmented data\n",
    "        ARR = [*ARR, train_set_one]\n",
    "\n",
    "    ARR = np.array(ARR)\n",
    "    # take the label and add them as the label for the new augmented data\n",
    "    LABEL = np.array(train_label[:,random_indices])\n",
    "\n",
    "#     we have ARR which is of shape (6, row, col) with the augmented data\n",
    "#     and train_set which is of shape (6, row, col) with the non augmented data\n",
    "    train_set_augmented = np.concatenate((train_set, ARR), axis = 1)\n",
    "    \n",
    "    label_set_augmented = np.concatenate((train_label, LABEL), axis=1)\n",
    "    print(label_set_augmented.shape)\n",
    "    print(train_set_augmented.shape)\n",
    "    print(\"end augmenting\")\n",
    "    return train_set_augmented,label_set_augmented\n",
    "\n",
    "# augment_data(train_set, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 692,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start augmenting\n",
      "(6, 3034, 2400)\n",
      "(1, 3034)\n",
      "(1, 5764)\n",
      "(6, 5764, 2400)\n",
      "end augmenting\n",
      "shape before dstack\n",
      "(6, 3034, 2400)\n",
      "(1, 3034)\n",
      "(6, 5764, 2400)\n",
      "(1, 5764)\n",
      "shape after dstack\n",
      "(3034, 2400, 6)\n",
      "(3034, 1)\n",
      "(5764, 2400, 6)\n",
      "(5764, 1)\n"
     ]
    }
   ],
   "source": [
    "# 4 is the number of sessions per user\n",
    "# train_set, train_label = create_datasets(0,4)\n",
    "# from 0 session to 5 session per user\n",
    "train_set, train_label, train_set_augmented, label_set_augmented =  create_datasets(0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 693,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start augmenting\n",
      "(6, 811, 2400)\n",
      "(1, 811)\n",
      "(1, 1540)\n",
      "(6, 1540, 2400)\n",
      "end augmenting\n",
      "shape before dstack\n",
      "(6, 811, 2400)\n",
      "(1, 811)\n",
      "(6, 1540, 2400)\n",
      "(1, 1540)\n",
      "shape after dstack\n",
      "(811, 2400, 6)\n",
      "(811, 1)\n",
      "(1540, 2400, 6)\n",
      "(1540, 1)\n"
     ]
    }
   ],
   "source": [
    "test_set, test_label, test_set_augmented, test_set_augmented = create_datasets(5,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_model(train_set, train_label) :\n",
    "    \n",
    "    print(train_set.shape)\n",
    "    print(train_label.shape)\n",
    "#     opt = Adam(learning_rate=0.01,beta_1=0.9,\n",
    "#     beta_2=0.999,\n",
    "#     epsilon=1e-07,\n",
    "#     amsgrad=False,\n",
    "#     name=\"Adam\")\n",
    "    \n",
    "    \n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(128, activation='relu', input_shape=(2400, 6), name=\"layer1\"))\n",
    "#     model.add(Dense(64, activation='relu', name=\"layer2\"))\n",
    "#     model.add(Dense(12, activation='relu', name=\"layer3\"))\n",
    "#     model.add(Dense(6, activation='relu', name=\"layer4\"))\n",
    "#     model.add(Dense(1, activation='sigmoid', name=\"layer5\"))\n",
    "\n",
    "#     model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "#     model.fit(np.array(train_set), np.array(train_label), epochs=50, batch_size=64)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(128, activation='relu', input_shape=(2400, 6)))\n",
    "    model.add(Dense(16, activation='relu'))\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt = Adam(learning_rate=0.001)\n",
    "\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    model.fit(np.array(train_set), np.array(train_label), epochs=30, batch_size=128)\n",
    "#     model.fit(train_data, train_data_labels, epochs=15, batch_size=128)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    acc = model.evaluate(test_set, test_label)\n",
    "#     print(acc)\n",
    "    return acc\n",
    "#     print(\"END network model\")\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 699,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3034, 2400, 6)\n",
      "(3034, 1)\n",
      "Epoch 1/30\n",
      "24/24 [==============================] - 3s 97ms/step - loss: 1.5158 - accuracy: 0.5301\n",
      "Epoch 2/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.6783 - accuracy: 0.5956\n",
      "Epoch 3/30\n",
      "24/24 [==============================] - 2s 96ms/step - loss: 0.6297 - accuracy: 0.6346\n",
      "Epoch 4/30\n",
      "24/24 [==============================] - 2s 96ms/step - loss: 0.6119 - accuracy: 0.6534\n",
      "Epoch 5/30\n",
      "24/24 [==============================] - 2s 96ms/step - loss: 0.6186 - accuracy: 0.6480\n",
      "Epoch 6/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.6036 - accuracy: 0.6619\n",
      "Epoch 7/30\n",
      "24/24 [==============================] - 2s 96ms/step - loss: 0.6059 - accuracy: 0.6568\n",
      "Epoch 8/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.6097 - accuracy: 0.6566\n",
      "Epoch 9/30\n",
      "24/24 [==============================] - 2s 96ms/step - loss: 0.6085 - accuracy: 0.6512\n",
      "Epoch 10/30\n",
      "24/24 [==============================] - 2s 96ms/step - loss: 0.5970 - accuracy: 0.6600\n",
      "Epoch 11/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5918 - accuracy: 0.6642\n",
      "Epoch 12/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5923 - accuracy: 0.6634\n",
      "Epoch 13/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5884 - accuracy: 0.6671\n",
      "Epoch 14/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5964 - accuracy: 0.6625\n",
      "Epoch 15/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5855 - accuracy: 0.6757\n",
      "Epoch 16/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5784 - accuracy: 0.6805\n",
      "Epoch 17/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5895 - accuracy: 0.6695\n",
      "Epoch 18/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5859 - accuracy: 0.6716\n",
      "Epoch 19/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5844 - accuracy: 0.6738\n",
      "Epoch 20/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5795 - accuracy: 0.6693\n",
      "Epoch 21/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5868 - accuracy: 0.6688\n",
      "Epoch 22/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5798 - accuracy: 0.6716\n",
      "Epoch 23/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5718 - accuracy: 0.6785\n",
      "Epoch 24/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5667 - accuracy: 0.6926\n",
      "Epoch 25/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5799 - accuracy: 0.6803\n",
      "Epoch 26/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5804 - accuracy: 0.6748\n",
      "Epoch 27/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5778 - accuracy: 0.6762\n",
      "Epoch 28/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5737 - accuracy: 0.6841\n",
      "Epoch 29/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5693 - accuracy: 0.6839\n",
      "Epoch 30/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5673 - accuracy: 0.6849\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5584 - accuracy: 0.7045\n",
      "(3034, 2400, 6)\n",
      "(3034, 1)\n",
      "Epoch 1/30\n",
      "24/24 [==============================] - 3s 97ms/step - loss: 1.1417 - accuracy: 0.5415\n",
      "Epoch 2/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.6570 - accuracy: 0.5989\n",
      "Epoch 3/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.6241 - accuracy: 0.6298\n",
      "Epoch 4/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.6115 - accuracy: 0.6497\n",
      "Epoch 5/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.6200 - accuracy: 0.6385\n",
      "Epoch 6/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5993 - accuracy: 0.6587\n",
      "Epoch 7/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5995 - accuracy: 0.6553\n",
      "Epoch 8/30\n",
      "24/24 [==============================] - 2s 99ms/step - loss: 0.5992 - accuracy: 0.6604\n",
      "Epoch 9/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5960 - accuracy: 0.6592\n",
      "Epoch 10/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5958 - accuracy: 0.6604\n",
      "Epoch 11/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.6040 - accuracy: 0.6562\n",
      "Epoch 12/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5895 - accuracy: 0.6702\n",
      "Epoch 13/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5884 - accuracy: 0.6603\n",
      "Epoch 14/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5798 - accuracy: 0.6733\n",
      "Epoch 15/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5816 - accuracy: 0.6710\n",
      "Epoch 16/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5821 - accuracy: 0.6737\n",
      "Epoch 17/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5822 - accuracy: 0.6721\n",
      "Epoch 18/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5821 - accuracy: 0.6728\n",
      "Epoch 19/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5791 - accuracy: 0.6762\n",
      "Epoch 20/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5794 - accuracy: 0.6752\n",
      "Epoch 21/30\n",
      "24/24 [==============================] - 2s 99ms/step - loss: 0.5758 - accuracy: 0.6782\n",
      "Epoch 22/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5759 - accuracy: 0.6817\n",
      "Epoch 23/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5772 - accuracy: 0.6784\n",
      "Epoch 24/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5717 - accuracy: 0.6800\n",
      "Epoch 25/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5675 - accuracy: 0.6938\n",
      "Epoch 26/30\n",
      "24/24 [==============================] - 2s 99ms/step - loss: 0.5709 - accuracy: 0.6849\n",
      "Epoch 27/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5671 - accuracy: 0.6843\n",
      "Epoch 28/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5726 - accuracy: 0.6817\n",
      "Epoch 29/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5585 - accuracy: 0.6928\n",
      "Epoch 30/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5708 - accuracy: 0.6834\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.5711 - accuracy: 0.6922\n",
      "(3034, 2400, 6)\n",
      "(3034, 1)\n",
      "Epoch 1/30\n",
      "24/24 [==============================] - 3s 97ms/step - loss: 1.3380 - accuracy: 0.5506\n",
      "Epoch 2/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.6698 - accuracy: 0.6032\n",
      "Epoch 3/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.6301 - accuracy: 0.6352\n",
      "Epoch 4/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.6123 - accuracy: 0.6499\n",
      "Epoch 5/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.6216 - accuracy: 0.6433\n",
      "Epoch 6/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.6157 - accuracy: 0.6477\n",
      "Epoch 7/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.6015 - accuracy: 0.6595\n",
      "Epoch 8/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.6051 - accuracy: 0.6521\n",
      "Epoch 9/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.6020 - accuracy: 0.6539\n",
      "Epoch 10/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5971 - accuracy: 0.6574\n",
      "Epoch 11/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.6026 - accuracy: 0.6526\n",
      "Epoch 12/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.6068 - accuracy: 0.6486\n",
      "Epoch 13/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5939 - accuracy: 0.6567\n",
      "Epoch 14/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5931 - accuracy: 0.6668\n",
      "Epoch 15/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5927 - accuracy: 0.6635\n",
      "Epoch 16/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5884 - accuracy: 0.6665\n",
      "Epoch 17/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5921 - accuracy: 0.6640\n",
      "Epoch 18/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5906 - accuracy: 0.6692\n",
      "Epoch 19/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5849 - accuracy: 0.6708 0s - loss: 0.5854 - \n",
      "Epoch 20/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5777 - accuracy: 0.6750\n",
      "Epoch 21/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5821 - accuracy: 0.6712\n",
      "Epoch 22/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5788 - accuracy: 0.6760 0s - loss: 0.5785 \n",
      "Epoch 23/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5764 - accuracy: 0.6745\n",
      "Epoch 24/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5857 - accuracy: 0.6618\n",
      "Epoch 25/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5685 - accuracy: 0.6910\n",
      "Epoch 26/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5773 - accuracy: 0.6789\n",
      "Epoch 27/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5680 - accuracy: 0.6848\n",
      "Epoch 28/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5754 - accuracy: 0.6771\n",
      "Epoch 29/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5727 - accuracy: 0.6813\n",
      "Epoch 30/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5742 - accuracy: 0.6818\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5693 - accuracy: 0.6877\n",
      "(3034, 2400, 6)\n",
      "(3034, 1)\n",
      "Epoch 1/30\n",
      "24/24 [==============================] - 3s 97ms/step - loss: 0.8830 - accuracy: 0.5593\n",
      "Epoch 2/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.6571 - accuracy: 0.6093\n",
      "Epoch 3/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.6261 - accuracy: 0.6318\n",
      "Epoch 4/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.6173 - accuracy: 0.6443\n",
      "Epoch 5/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.6024 - accuracy: 0.6533\n",
      "Epoch 6/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.6072 - accuracy: 0.6536\n",
      "Epoch 7/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5987 - accuracy: 0.6566\n",
      "Epoch 8/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.6016 - accuracy: 0.6591\n",
      "Epoch 9/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5938 - accuracy: 0.6644\n",
      "Epoch 10/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5963 - accuracy: 0.6619\n",
      "Epoch 11/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5839 - accuracy: 0.6727\n",
      "Epoch 12/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5919 - accuracy: 0.6612\n",
      "Epoch 13/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5917 - accuracy: 0.6674\n",
      "Epoch 14/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5827 - accuracy: 0.6781\n",
      "Epoch 15/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5760 - accuracy: 0.6802\n",
      "Epoch 16/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5743 - accuracy: 0.6763\n",
      "Epoch 17/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5793 - accuracy: 0.6777\n",
      "Epoch 18/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5766 - accuracy: 0.6840\n",
      "Epoch 19/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5696 - accuracy: 0.6902\n",
      "Epoch 20/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5781 - accuracy: 0.6803\n",
      "Epoch 21/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5606 - accuracy: 0.6964\n",
      "Epoch 22/30\n",
      "24/24 [==============================] - 2s 99ms/step - loss: 0.5735 - accuracy: 0.6837\n",
      "Epoch 23/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5637 - accuracy: 0.6908\n",
      "Epoch 24/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5733 - accuracy: 0.6835\n",
      "Epoch 25/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5741 - accuracy: 0.6867\n",
      "Epoch 26/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5653 - accuracy: 0.6879\n",
      "Epoch 27/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5740 - accuracy: 0.6842\n",
      "Epoch 28/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5592 - accuracy: 0.6969\n",
      "Epoch 29/30\n",
      "24/24 [==============================] - 2s 98ms/step - loss: 0.5633 - accuracy: 0.6951\n",
      "Epoch 30/30\n",
      "24/24 [==============================] - 2s 97ms/step - loss: 0.5624 - accuracy: 0.6918\n",
      "26/26 [==============================] - 0s 10ms/step - loss: 0.5601 - accuracy: 0.7059\n",
      "69.75736767053604\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network with the original data\n",
    "acc = 0\n",
    "for i in range(4):\n",
    "#     print(network_model(train_set,train_label))\n",
    "    acc += network_model(train_set,train_label)[1]\n",
    "\n",
    "print(acc/4 * 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5764, 2400, 6)\n",
      "(5764, 1)\n",
      "Epoch 1/30\n",
      "46/46 [==============================] - 5s 98ms/step - loss: 0.9556 - accuracy: 0.5373\n",
      "Epoch 2/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6585 - accuracy: 0.6030\n",
      "Epoch 3/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6429 - accuracy: 0.6244\n",
      "Epoch 4/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6294 - accuracy: 0.6328\n",
      "Epoch 5/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6717 - accuracy: 0.6023\n",
      "Epoch 6/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6229 - accuracy: 0.6404\n",
      "Epoch 7/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6180 - accuracy: 0.6500\n",
      "Epoch 8/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6392 - accuracy: 0.6161\n",
      "Epoch 9/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6110 - accuracy: 0.6551\n",
      "Epoch 10/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6072 - accuracy: 0.6599\n",
      "Epoch 11/30\n",
      "46/46 [==============================] - 4s 98ms/step - loss: 0.6046 - accuracy: 0.6580\n",
      "Epoch 12/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.5995 - accuracy: 0.6601\n",
      "Epoch 13/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.5953 - accuracy: 0.6702\n",
      "Epoch 14/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6036 - accuracy: 0.6664\n",
      "Epoch 15/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.5945 - accuracy: 0.6657\n",
      "Epoch 16/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.5995 - accuracy: 0.6649\n",
      "Epoch 17/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6106 - accuracy: 0.6510\n",
      "Epoch 18/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6309 - accuracy: 0.6467\n",
      "Epoch 19/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6025 - accuracy: 0.6612\n",
      "Epoch 20/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6073 - accuracy: 0.6592\n",
      "Epoch 21/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.5946 - accuracy: 0.6707\n",
      "Epoch 22/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5913 - accuracy: 0.6734\n",
      "Epoch 23/30\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 0.5875 - accuracy: 0.6774\n",
      "Epoch 24/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5902 - accuracy: 0.6766\n",
      "Epoch 25/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5869 - accuracy: 0.6772\n",
      "Epoch 26/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5999 - accuracy: 0.6651\n",
      "Epoch 27/30\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 0.5926 - accuracy: 0.6759\n",
      "Epoch 28/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5897 - accuracy: 0.6721\n",
      "Epoch 29/30\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 0.5859 - accuracy: 0.6804\n",
      "Epoch 30/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5961 - accuracy: 0.6653\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5766 - accuracy: 0.7105\n",
      "(5764, 2400, 6)\n",
      "(5764, 1)\n",
      "Epoch 1/30\n",
      "46/46 [==============================] - 5s 95ms/step - loss: 1.0803 - accuracy: 0.5423\n",
      "Epoch 2/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6539 - accuracy: 0.5953\n",
      "Epoch 3/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6351 - accuracy: 0.6203\n",
      "Epoch 4/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6187 - accuracy: 0.6356\n",
      "Epoch 5/30\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 0.6253 - accuracy: 0.6347\n",
      "Epoch 6/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6160 - accuracy: 0.6436\n",
      "Epoch 7/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6181 - accuracy: 0.6451\n",
      "Epoch 8/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6097 - accuracy: 0.6457\n",
      "Epoch 9/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6125 - accuracy: 0.6483\n",
      "Epoch 10/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6121 - accuracy: 0.6471\n",
      "Epoch 11/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6077 - accuracy: 0.6522\n",
      "Epoch 12/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6118 - accuracy: 0.6428\n",
      "Epoch 13/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6029 - accuracy: 0.6572\n",
      "Epoch 14/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.5968 - accuracy: 0.6604\n",
      "Epoch 15/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6069 - accuracy: 0.6528\n",
      "Epoch 16/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6107 - accuracy: 0.6494\n",
      "Epoch 17/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6058 - accuracy: 0.6530\n",
      "Epoch 18/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6053 - accuracy: 0.6542\n",
      "Epoch 19/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6033 - accuracy: 0.6605\n",
      "Epoch 20/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.5880 - accuracy: 0.6747\n",
      "Epoch 21/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5968 - accuracy: 0.6616\n",
      "Epoch 22/30\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 0.6035 - accuracy: 0.6582\n",
      "Epoch 23/30\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 0.6029 - accuracy: 0.6593\n",
      "Epoch 24/30\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 0.5873 - accuracy: 0.6755\n",
      "Epoch 25/30\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 0.5938 - accuracy: 0.6694\n",
      "Epoch 26/30\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 0.5840 - accuracy: 0.6821\n",
      "Epoch 27/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5868 - accuracy: 0.6761\n",
      "Epoch 28/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5968 - accuracy: 0.6694\n",
      "Epoch 29/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5876 - accuracy: 0.6785\n",
      "Epoch 30/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5867 - accuracy: 0.6772\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5735 - accuracy: 0.6857\n",
      "(5764, 2400, 6)\n",
      "(5764, 1)\n",
      "Epoch 1/30\n",
      "46/46 [==============================] - 5s 96ms/step - loss: 0.7068 - accuracy: 0.5827\n",
      "Epoch 2/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6376 - accuracy: 0.6296\n",
      "Epoch 3/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6196 - accuracy: 0.6422\n",
      "Epoch 4/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6315 - accuracy: 0.6200\n",
      "Epoch 5/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6153 - accuracy: 0.6458\n",
      "Epoch 6/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6195 - accuracy: 0.6466\n",
      "Epoch 7/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6077 - accuracy: 0.6547\n",
      "Epoch 8/30\n",
      "46/46 [==============================] - 5s 101ms/step - loss: 0.6033 - accuracy: 0.6568\n",
      "Epoch 9/30\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 0.6359 - accuracy: 0.6072\n",
      "Epoch 10/30\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 0.6204 - accuracy: 0.6330\n",
      "Epoch 11/30\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 0.6040 - accuracy: 0.6569\n",
      "Epoch 12/30\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 0.6035 - accuracy: 0.6546\n",
      "Epoch 13/30\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 0.5962 - accuracy: 0.6647\n",
      "Epoch 14/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5995 - accuracy: 0.6639\n",
      "Epoch 15/30\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 0.5938 - accuracy: 0.6636\n",
      "Epoch 16/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5968 - accuracy: 0.6642\n",
      "Epoch 17/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5915 - accuracy: 0.6674\n",
      "Epoch 18/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5925 - accuracy: 0.6693\n",
      "Epoch 19/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5960 - accuracy: 0.6657\n",
      "Epoch 20/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5827 - accuracy: 0.6755\n",
      "Epoch 21/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5847 - accuracy: 0.6738\n",
      "Epoch 22/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5881 - accuracy: 0.6804\n",
      "Epoch 23/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5786 - accuracy: 0.6838\n",
      "Epoch 24/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5833 - accuracy: 0.6806\n",
      "Epoch 25/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5868 - accuracy: 0.6808\n",
      "Epoch 26/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5844 - accuracy: 0.6840\n",
      "Epoch 27/30\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 0.5902 - accuracy: 0.6776\n",
      "Epoch 28/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5784 - accuracy: 0.6832\n",
      "Epoch 29/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5810 - accuracy: 0.6785\n",
      "Epoch 30/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5800 - accuracy: 0.6842\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5977 - accuracy: 0.6705\n",
      "(5764, 2400, 6)\n",
      "(5764, 1)\n",
      "Epoch 1/30\n",
      "46/46 [==============================] - 5s 96ms/step - loss: 1.0715 - accuracy: 0.5423\n",
      "Epoch 2/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6458 - accuracy: 0.6109\n",
      "Epoch 3/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6397 - accuracy: 0.6256\n",
      "Epoch 4/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6226 - accuracy: 0.6400\n",
      "Epoch 5/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6257 - accuracy: 0.6350\n",
      "Epoch 6/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6190 - accuracy: 0.6405\n",
      "Epoch 7/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6745 - accuracy: 0.6116\n",
      "Epoch 8/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6205 - accuracy: 0.6407\n",
      "Epoch 9/30\n",
      "46/46 [==============================] - 4s 95ms/step - loss: 0.6104 - accuracy: 0.6459\n",
      "Epoch 10/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6065 - accuracy: 0.6563\n",
      "Epoch 11/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6130 - accuracy: 0.6495\n",
      "Epoch 12/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5967 - accuracy: 0.6620\n",
      "Epoch 13/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5957 - accuracy: 0.6595 1s - l\n",
      "Epoch 14/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6035 - accuracy: 0.6538\n",
      "Epoch 15/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6011 - accuracy: 0.6577\n",
      "Epoch 16/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6062 - accuracy: 0.6576\n",
      "Epoch 17/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.5944 - accuracy: 0.6649\n",
      "Epoch 18/30\n",
      "46/46 [==============================] - 4s 96ms/step - loss: 0.6312 - accuracy: 0.6379\n",
      "Epoch 19/30\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 0.5947 - accuracy: 0.6637\n",
      "Epoch 20/30\n",
      "46/46 [==============================] - 4s 97ms/step - loss: 0.6067 - accuracy: 0.6503\n",
      "Epoch 21/30\n",
      "46/46 [==============================] - 5s 98ms/step - loss: 0.6017 - accuracy: 0.6598\n",
      "Epoch 22/30\n",
      "46/46 [==============================] - 4s 98ms/step - loss: 0.5947 - accuracy: 0.6666\n",
      "Epoch 23/30\n",
      "46/46 [==============================] - 4s 98ms/step - loss: 0.5952 - accuracy: 0.6658\n",
      "Epoch 24/30\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 0.6049 - accuracy: 0.6572\n",
      "Epoch 25/30\n",
      "46/46 [==============================] - 4s 98ms/step - loss: 0.5938 - accuracy: 0.6661\n",
      "Epoch 26/30\n",
      "46/46 [==============================] - 5s 98ms/step - loss: 0.5905 - accuracy: 0.6736\n",
      "Epoch 27/30\n",
      "46/46 [==============================] - 5s 98ms/step - loss: 0.5855 - accuracy: 0.6809\n",
      "Epoch 28/30\n",
      "46/46 [==============================] - 5s 99ms/step - loss: 0.5867 - accuracy: 0.6747\n",
      "Epoch 29/30\n",
      "46/46 [==============================] - 5s 98ms/step - loss: 0.6119 - accuracy: 0.6494\n",
      "Epoch 30/30\n",
      "46/46 [==============================] - 5s 98ms/step - loss: 0.5953 - accuracy: 0.6673\n",
      "26/26 [==============================] - 0s 11ms/step - loss: 0.5792 - accuracy: 0.6679\n",
      "68.3631181716919\n"
     ]
    }
   ],
   "source": [
    "# evaluate the network with the augmented data\n",
    "acc = 0\n",
    "for i in range(4):\n",
    "    acc += network_model(train_set_augmented, label_set_augmented)[1]\n",
    "\n",
    "print(acc/4 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def scale(X, sigma=0.1):\n",
    "#     # (104, 6, 2400)\n",
    "#     scalingFactor = np.random.normal(loc=1.0, scale=sigma, size=(X.shape[0],X.shape[1],X.shape[2])) # shape=(1,6)\n",
    "# #     print(scalingFactor.shape)\n",
    "# #     myNoise = np.matmul(np.ones((X.shape[0],1)), scalingFactor)\n",
    "# #     print(myNoise.shape)\n",
    "# #     return X*myNoise\n",
    "#     return X * scalingFactor\n",
    "# # train_set3_new = new_set_train\n",
    "# # scale(train_set3_new)\n",
    "\n",
    "def scale(X, sigma=0.1):\n",
    "    scalingFactor = np.random.normal(loc=1.0, scale=sigma, size=(1, X.shape[1]))  # shape=(1,3)\n",
    "    myNoise = np.matmul(np.ones((X.shape[0], 1)), scalingFactor)\n",
    "    return X * myNoise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 698,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GenerateRandomCurves(X, sigma=0.2, knot=4):\n",
    "    xx = (np.ones((X.shape[1], 1)) * (np.arange(0, X.shape[0], (X.shape[0] - 1) / (knot + 1)))).transpose()\n",
    "    yy = np.random.normal(loc=1.0, scale=sigma, size=(knot + 2, X.shape[1]))\n",
    "    x_range = np.arange(X.shape[0])\n",
    "    random_curves = []\n",
    "    for i in range(X.shape[-1]):\n",
    "        cs = CubicSpline(xx[:, i], yy[:, i])\n",
    "        random_curves.append(cs(x_range))\n",
    "    return np.array(random_curves).transpose()\n",
    "\n",
    "def DA_MagWarp(X, sigma=0.2):\n",
    "    return X * GenerateRandomCurves(X, sigma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dstack and transpose. \n",
    "# after transpose i have a row of 2400 that contains eda, the second row of 2400 with bvp etc..\n",
    "# i augment every row, then i traspose back so i return in the dstack state and i run the neural network\n",
    "# to augment i select randomly 50 % of the windows and i add it as new dimensions.\n",
    "# (Otherwise i can augment the nan so fill the holes?????)\n",
    "\n",
    "# if number of row is 100, take 50\n",
    "# shape (208, 2400, 6)\n",
    "number_of_rows = int(train_set.shape[0] * 0.5)\n",
    "# print(train_set.shape)\n",
    "# print(number_of_rows)\n",
    "# transpose so that the cols become row. in this way we have a row that is 2400 long (a window)\n",
    "train_set2 = train_set.transpose((0, 2, 1))\n",
    "# print(train_set2.shape)\n",
    "\n",
    "\n",
    "# select random indices\n",
    "random_indices = np.sort(np.random.choice(train_set.shape[0]-1, size=number_of_rows, replace=False))\n",
    "\n",
    "# take partial array with random indices\n",
    "new_set_train = train_set2[random_indices,:]\n",
    "# take the label and add them as the label for the new augmented data\n",
    "new_set_label = train_label[random_indices]\n",
    "\n",
    "# perform jittering on the partial array\n",
    "# print(new_set_train.shape)\n",
    "# (104, 6, 2400)\n",
    "# print(new_set_train[0,0,0])\n",
    "new_set_train = jitter(new_set_train)\n",
    "\n",
    "# print(new_set_train[0,0,0])\n",
    "# new_set_train = scale(new_set_train)\n",
    "# print(new_set_train.shape)\n",
    "\n",
    "\n",
    "\n",
    "new_set_to_predict = new_set_train.transpose((0, 2, 1))\n",
    "# print(new_set_to_predict.shape)\n",
    "# label_pred = model.predict(new_set_to_predict)\n",
    "# (104, 2400, 1)\n",
    "# print(new_set_to_predict.shape)\n",
    "\n",
    "\n",
    "# add the augmented array as new dimensions and run the neural network \n",
    "train_set2 = np.concatenate((train_set2, new_set_train), axis = 0)\n",
    "train_label2 = np.concatenate((train_label, new_set_label))\n",
    "\n",
    "\n",
    "\n",
    "# converto back to transpose, like after the dstack\n",
    "train_set2 = train_set2.transpose((0, 2, 1))\n",
    "\n",
    "print(\"train_set\")\n",
    "print(train_set.shape)\n",
    "print(train_set2.shape)\n",
    "print(\"train_label\")\n",
    "print(train_label.shape)\n",
    "print(train_label2.shape)\n",
    "\n",
    "\n",
    "model = network_model(train_set2,train_label2)\n",
    "\n",
    "# print(train_set.shape)\n",
    "# opt = Adam(learning_rate=0.001,beta_1=0.9,\n",
    "# beta_2=0.999,\n",
    "# epsilon=1e-07,\n",
    "# amsgrad=False,\n",
    "# name=\"Adam\")\n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(32, activation='relu', input_shape=(2400, 6), name=\"layer1\"))\n",
    "# model.add(Dense(12, activation='relu', name=\"layer2\"))\n",
    "# model.add(Dense(1, activation='sigmoid', name=\"layer3\"))\n",
    "\n",
    "# model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "# model.fit(np.array(train_set2), np.array(train_label2), epochs=100, batch_size=64)\n",
    "\n",
    "    \n",
    "# model.predict(test_set)\n",
    "\n",
    "# accuracy = accuracy_score()\n",
    "# fig = plt.figure(figsize=(15,4))\n",
    "# for ii in range(8):\n",
    "#     ax = fig.add_subplot(2,4,ii+1)\n",
    "#     ax.plot(DA_Jitter(eda, sigma))\n",
    "#     ax.set_xlim([0,2400])\n",
    "#     ax.set_ylim([-0.5,1.5])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# network_model(train_set2,train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# 3600 samples (Time) * 3 features (X,Y,Z)\n",
    "# take two dimensions array\n",
    "\n",
    "# [[acc_x_0], [acc_y_0], [acc_z_0]]\n",
    "eda = train_set[0][0]\n",
    "bvp = train_set[1][0]\n",
    "acc_x_0 = train_set[2][0]\n",
    "acc_y_0 = train_set[3][0]\n",
    "acc_z_0 = train_set[4][0]\n",
    "tem = train_set[5][0]\n",
    "\n",
    "\n",
    "array_to_plot = np.array([acc_x_0,acc_y_0,acc_z_0], dtype=np.float64)\n",
    "# plt.plot(array_to_plot)\n",
    "\n",
    "# plt.plot(acc_x_0, color='g')\n",
    "# plt.plot(acc_y_0, color='r')\n",
    "# plt.plot(acc_z_0, color='b')\n",
    "# plt.title(\"A window of 10 min Acceleration data\")\n",
    "# plt.axis([0,2400,-100,100])\n",
    "# plt.xlabel(\"time\")\n",
    "# plt.ylabel(\"value acc\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "plt.plot(eda, color='g')\n",
    "plt.title(\"A window of 10 min Electrodermal Activity data\")\n",
    "plt.axis([0,2400,-0.5,1.5])\n",
    "plt.xlabel(\"time\")\n",
    "plt.ylabel(\"value acc\")\n",
    "plt.show()\n",
    "\n",
    "# plt.plot(bvp, color='g')\n",
    "# plt.title(\"A window of 10 min Blood Volume Pulse data\")\n",
    "# plt.axis([0,2400,-450, 450])\n",
    "# plt.xlabel(\"time\")\n",
    "# plt.ylabel(\"value acc\")\n",
    "# plt.show()\n",
    "\n",
    "# plt.plot(tem, color='g')\n",
    "# plt.title(\"A window of 10 min Skin Temperature data\")\n",
    "# plt.axis([0,2400,28, 29.5])\n",
    "# plt.xlabel(\"time\")\n",
    "# plt.ylabel(\"value acc\")\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "sigma = 0.05\n",
    "\n",
    "def DA_Jitter(X, sigma=0.05):\n",
    "    myNoise = np.random.normal(loc=0, scale=sigma, size=X.shape)\n",
    "    return X+myNoise\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15,4))\n",
    "for ii in range(8):\n",
    "    ax = fig.add_subplot(2,4,ii+1)\n",
    "    ax.plot(DA_Jitter(eda, sigma))\n",
    "    ax.set_xlim([0,2400])\n",
    "    ax.set_ylim([-0.5,1.5])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA = np.array([[111,112,113,114], [4,122,123,54],[121,32,123,4],[121,32,123,4],[121,32,123,4]])\n",
    "BVP = np.array([[1,2,3,4], [5,6,7,8],[2,4,234,43],[2,4,234,43],[121,32,123,4]])\n",
    "ACC = np.array([[34,45,23,46], [78,456,49,70],[34,221,42,436],[2,4333,234,43],[121,32,123,4]])\n",
    "\n",
    "train_data = np.array([EDA, BVP, ACC])\n",
    "# print(train_data)\n",
    "print(train_data.shape)\n",
    "# number_of_rows = train_data.shape[0]\n",
    "# random_indices = np.random.choice(number_of_rows, \n",
    "#                                   size=3, \n",
    "#                                   replace=False)\n",
    "print(\" -- \")\n",
    "# row = train_data[:, random_indices]\n",
    "# print(row)\n",
    "# train_data_labels = np.array([[0], [1]])\n",
    "# print(train_data)\n",
    "# train_data.shape  # (3, 2, 7)\n",
    "\n",
    "\n",
    "train_data_2 = np.dstack(train_data)\n",
    "# print(train_data_2)\n",
    "print(train_data_2.shape)\n",
    "print(\" -- \")\n",
    "# train_data = train_data.reshape(2,3,4)\n",
    "\n",
    "train_data_3 = train_data_2.transpose((0, 2, 1))\n",
    "# print(train_data_3)\n",
    "print(train_data_3.shape)\n",
    "\n",
    "print(\" -- \")\n",
    "# total size from which take the random numbers, how many numbers to take\n",
    "# choice(208, 104, false)\n",
    "random_indices = np.random.choice(train_data_3.shape[1], size=1, replace=False)\n",
    "# random_indices = np.sort(random_indices)\n",
    "print(random_indices)\n",
    "row = train_data_3[random_indices]\n",
    "# print(row)\n",
    "print()\n",
    "scalingFactor = np.random.normal(loc=1.0, scale=0.1, size=(1,row.shape[1], 4)) # shape (1,3)\n",
    "print(scalingFactor.shape)\n",
    "# print(scalingFactor)\n",
    "print(row.shape)\n",
    "scalingMatrix = row * scalingFactor\n",
    "# print(np.ones((row.shape[0],1)))\n",
    "# myNoise = np.matmul(np.ones((row.shape[0],1)), scalingFactor)\n",
    "# print(myNoise)\n",
    "\n",
    "print(scalingFactor)\n",
    "print(scalingMatrix)\n",
    "print(row)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
